<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet href="urn:x-suse:xslt:profiling:docbook51-profile.xsl"
 type="text/xml"
 title="Profiling step"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "generic-entities.ent">
    %entities;
  <!ENTITY graf-config-icon "<inlinemediaobject xmlns='http://docbook.org/ns/docbook'><textobject role='description'><phrase>Gear icon, Configuration</phrase></textobject><imageobject role='fo'><imagedata fileref='grafana-configuration.png' width='0.8em' format='PNG'/></imageobject><imageobject role='html'><imagedata fileref='grafana-configuration.png' width='1em' format='PNG'/></imageobject></inlinemediaobject>">
  <!ENTITY graf-create-icon "<inlinemediaobject xmlns='http://docbook.org/ns/docbook'><textobject role='description'><phrase>Plus icon, Create</phrase></textobject><imageobject role='fo'><imagedata fileref='grafana-create.png' width='0.8em' format='PNG'/></imageobject><imageobject role='html'><imagedata fileref='grafana-create.png' width='1em' format='PNG'/></imageobject></inlinemediaobject>">
]>

<chapter xml:id="cha-monitoring" xml:lang="en"
 xmlns="http://docbook.org/ns/docbook" version="5.1"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <title>Monitoring and logging</title>
 <info>
  <abstract>
   <para>
    Obtaining and maintaining an overview over the status and health
    of a compute cluster nodes helps to ensure a smooth operation.
    A number of tools are provided which give an administrator an
    overview over the current cluster status, collect system
    logs and gather information on certain system failures conditions.
   </para>
  </abstract>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
  <sect1 xml:id="sec-remote-conman">
  <title>ConMan &mdash; the console manager</title>
  <para>
   ConMan is a serial console management program designed to support a
   large number of console devices and simultaneous users. It supports:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     local serial devices
    </para>
   </listitem>
   <listitem>
    <para>
     remote terminal servers (via the telnet protocol)
    </para>
   </listitem>
   <listitem>
    <para>
     IPMI Serial-Over-LAN (via FreeIPMI)
    </para>
   </listitem>
   <listitem>
    <para>
     Unix domain sockets
    </para>
   </listitem>
   <listitem>
    <para>
     external processes (for example, using <command>expect</command> scripts
     for <command>telnet</command>, <command>ssh</command>, or
     <command>ipmi-sol</command> connections)
    </para>
   </listitem>
  </itemizedlist>
  <para>
   ConMan can be used for monitoring, logging and optionally timestamping
   console device output.
  </para>
  <para>
   To install ConMan, run <literal>zypper in conman</literal>.
  </para>
  <important>
   <title><systemitem class="daemon">conmand</systemitem> sends unencrypted data</title>
   <para>
    The daemon <systemitem class="daemon">conmand</systemitem> sends
    unencrypted data over the
    network and its connections are not authenticated. Therefore, it should
    be used locally only: Listening to the port
    <literal>localhost</literal>. However, the IPMI console does offer
    encryption. This makes <literal>conman</literal> a good tool for
    monitoring a large number of such consoles.
   </para>
  </important>
  <para>
   Usage:
  </para>
  <itemizedlist>
   <listitem>
    <para>
     ConMan comes with a number of expect-scripts. They can be found in the
     directory <filename>/usr/lib/conman/exec</filename>.
    </para>
   </listitem>
   <listitem>
    <para>
     Input to <literal>conman</literal> is not echoed in interactive mode.
     This can be changed by entering the escape sequence
     <literal>&amp;E</literal>.
    </para>
   </listitem>
   <listitem>
    <para>
     When pressing <keycap function="enter"/> in interactive mode, no line
     feed is generated. To generate a line feed, press
     <keycombo><keycap function="control"/><keycap>L</keycap></keycombo>.
    </para>
   </listitem>
  </itemizedlist>
  <para>
   For more information about options, see the man page of ConMan.
  </para>
 </sect1>
 <sect1 xml:id="sec-monitoring-clusters-prometheus">
  <title>Monitoring &hpc; clusters</title>
  <para>
   You can monitor clusters in &productname; using &prometheus; and &grafana;.
  </para>
  <para>
   &prometheus; collects metrics from exporters that run on the machines in the
   cluster, and stores the data in a time series database. &grafana; provides
   data visualization dashboards for the metrics collected by &prometheus;.
   You can download pre-configured dashboards from the &grafana; website.
  </para>
  <para>
   The following &prometheus; exporters are useful for &hpc;:
  </para>
  <variablelist>
   <varlistentry>
    <term>&slurm; exporter</term>
    <listitem>
     <para>
      Extracts job and job queue status metrics from the &slurm; workload manager.
      Install this exporter on the management server, or on a node that can
      access the same &slurm; configuration and has access to the cluster.
     </para>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Node exporter</term>
    <listitem>
     <para>
      Extracts hardware and kernel performance metrics directly from each compute
      node. Install this exporter on every compute node you want to monitor.
     </para>
    </listitem>
   </varlistentry>
  </variablelist>
  <itemizedlist>
   <title>More information</title>
   <listitem>
    <para>
     &grafana;:
     <link xlink:href="https://grafana.com/docs/grafana/latest/getting-started/"/>
    </para>
   </listitem>
   <listitem>
    <para>
     &grafana; dashboards:
     <link xlink:href="https://grafana.com/grafana/dashboards"/>
    </para>
   </listitem>
   <listitem>
    <para>
     &prometheus;:
     <link xlink:href="https://prometheus.io/docs/introduction/overview/"/>
    </para>
   </listitem>
   <listitem>
    <para>
     &prometheus; exporters:
     <link xlink:href="https://prometheus.io/docs/instrumenting/exporters/"/>
    </para>
   </listitem>
   <listitem>
    <para>
     &slurm; exporter:
     <link xlink:href="https://github.com/vpenso/prometheus-slurm-exporter"/>
    </para>
   </listitem>
   <listitem>
    <para>
     Node exporter:
     <link xlink:href="https://github.com/prometheus/node_exporter"/>
    </para>
   </listitem>
  </itemizedlist>
  <sect2 xml:id="sec-installing-prometheus-grafana">
   <title>Installing &prometheus; and &grafana;</title>
   <para>
    You can install &prometheus; and &grafana; on the management server, or on a
    separate monitoring server.
   </para>
   <itemizedlist>
    <title>Prerequisites</title>
    <listitem>
     <para>
      You have an installation source for &prometheus; and &grafana;:
     </para>
     <itemizedlist>
      <listitem>
       <para>
        If you use &susemgr;, the packages are available from the
        &susemgr; Client Tools repository.
       </para>
      </listitem>
      <listitem>
       <para>
        If you do not use &susemgr;, the packages are available from &ph;.
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
    <listitem>
     <para>
      You have access to a graphical environment to view the &grafana; web server.
     </para>
    </listitem>
   </itemizedlist>
   <procedure xml:id="pro-installing-prometheus-grafana">
    <title>Installing &prometheus; and &grafana;</title>
    <para>
    In this procedure, replace <literal>example.com</literal> with the FQDN or
    IP address of the server where &prometheus; and &grafana; are installed.
   </para>
    <step>
     <para>
      Install the &prometheus; and &grafana; packages:
     </para>
<screen>&prompt.root;zypper in golang-github-prometheus-prometheus grafana</screen>
    </step>
    <step>
     <para>
      Enable and start &prometheus;:
     </para>
<screen>&prompt.root;systemctl enable --now prometheus</screen>
    </step>
    <step>
     <para>
      Verify that &prometheus; works:
     </para>
     <stepalternatives>
      <step>
       <para>
        In your browser, navigate to <link xlink:href="http://&exampledomain;:9090/config"/>,
        or:
       </para>
      </step>
      <step>
       <para>
        In your terminal, run the following command:
       </para>
<screen>&prompt.user;wget http://&exampledomain;:9090/config --output-document=-</screen>
      </step>
     </stepalternatives>
     <para>
      Either of these methods should show the default contents of the
      <filename>/etc/prometheus/prometheus.yml</filename> file.
     </para>
    </step>
    <step>
     <para>
      Enable and start &grafana;:
     </para>
<screen>&prompt.root;systemctl enable --now grafana-server</screen>
    </step>
    <step>
     <para>
      Log in to the &grafana; web server at
      <link xlink:href="http://&exampledomain;:3000"/>.
     </para>
     <para>
      Use <literal>admin</literal> for both the user name and password, then
      change your password when prompted.
     </para>
    </step>
    <step>
     <para>
      On the left panel, select &graf-config-icon; and click <guimenu>Data Sources</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Click <guimenu>Add data source</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Find &prometheus; and click <guimenu>Select</guimenu>.
     </para>
    </step>
    <step>
     <para>
      In the <guimenu>URL</guimenu> field, enter <literal>http://localhost:9090</literal>.
      You can keep the default settings for the other fields.
     </para>
    </step>
    <step>
     <para>
      Click <guimenu>Save &amp; Test</guimenu>.
     </para>
    </step>
   </procedure>
   <!-- Troubleshooting? What if Save & Test returns an error? -->
   <para>
    You can now configure &prometheus; to collect metrics from your cluster, and
    add dashboards to &grafana; to visualize those metrics.
   </para>
  </sect2>
  <sect2 xml:id="sec-monitoring-cluster-workloads">
   <title>Monitoring cluster workloads</title>
   <para>
    You can monitor cluster workloads using the &prometheus; &slurm; exporter.
    The &slurm; exporter gathers job and job queue status metrics from the
    &slurm; workload manager. To visualize these metrics, you can import a
    custom dashboard from the &grafana; website. For more information, see
    <link xlink:href="https://grafana.com/grafana/dashboards/4323"/>.
   </para>
   <important>
    <title>&slurm; exporter fails when GPU monitoring is enabled</title>
    <para>
     In &slurm; 20.11, the &slurm; exporter fails when GPU monitoring is enabled.
    </para>
    <para>
     This feature is disabled by default. Do not enable it for this version of &slurm;.
    </para>
   </important>
   <itemizedlist>
    <title>Prerequisites</title>
    <listitem>
     <para>
      <xref linkend="sec-installing-prometheus-grafana"/> is complete.
     </para>
    </listitem>
    <listitem>
     <para>
      The &slurm; workload manager is fully configured.
     </para>
    </listitem>
    <listitem>
     <para>
      You have internet access and policies that allow you to download the
      dashboard from the &grafana; website.
     </para>
    </listitem>
   </itemizedlist>
   <procedure xml:id="pro-monitoring-cluster-workloads">
    <title>Monitoring cluster workloads</title>
    <para>
     In this procedure, replace <literal>mgmt.&exampledomain;</literal> with the
     FQDN or IP address of the management server, and replace
     <literal>&exampledomain;</literal> with the FQDN or IP address of the
     server where &grafana; is installed.
    </para>
    <step>
     <para>
      On the management server, install the &slurm; exporter:
     </para>
<screen>&prompt.root;zypper in golang-github-vpenso-prometheus_slurm_exporter</screen>
    </step>
    <step>
     <para>
      Enable and start the &slurm; exporter:
    </para>
<screen>&prompt.root;systemctl enable --now prometheus-slurm_exporter</screen>
    </step>
    <step>
     <para>
      Verify that the &slurm; exporter works:
     </para>
     <stepalternatives>
      <step>
       <para>
        In your browser, navigate to
        <link xlink:href="http://mgmt.&exampledomain;:8080/metrics"/>, or:
       </para>
      </step>
      <step>
       <para>
        In your terminal, run the following command:
       </para>
<screen>&prompt.user;wget http://mgmt.&exampledomain;:8080/metrics --output-document=-</screen>
      </step>
     </stepalternatives>
     <para>
      Either of these methods should show output similar to the following:
     </para>
<screen># HELP go_gc_duration_seconds A summary of the GC invocation durations.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 1.9521e-05
go_gc_duration_seconds{quantile="0.25"} 4.5717e-05
go_gc_duration_seconds{quantile="0.5"} 7.8573e-05
...</screen>
    </step>
    <step>
     <para>
      On the server where &prometheus; is installed, edit the
      <literal>scrape_configs</literal> section of the
      <filename>/etc/prometheus/prometheus.yml</filename> file to
      add a job for the &slurm; exporter:
     </para>
 <screen>  - job_name: slurm-exporter
     scrape_interval: 30s
     scrape_timeout: 30s
     static_configs:
       - targets: ['mgmt.&exampledomain;:8080']
</screen>
     <para>
      Set the <literal>scrape_interval</literal> and <literal>scrape_timeout</literal>
      to <literal>30s</literal> to avoid overloading the management server.
     </para>
    </step>
    <step>
     <para>
      Restart the &prometheus; service:
     </para>
     <screen>&prompt.root;systemctl restart prometheus</screen>
    </step>
    <step>
     <para>
      Log in to the &grafana; web server at <link xlink:href="http://&exampledomain;:3000"/>.
     </para>
    </step>
    <step>
     <para>
      On the left panel, select &graf-create-icon; and click <guimenu>Import</guimenu>.
     </para>
    </step>
    <step>
     <para>
      In the <guimenu>Import via grafana.com</guimenu> field, enter the dashboard
      ID <literal>4323</literal>, then click <guimenu>Load</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Select <guimenu>&prometheus;</guimenu> from the
      <guimenu>Select a &prometheus; data source</guimenu> drop-down box, then
      click <guimenu>Import</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Review the &slurm; dashboard. The data might take some time to appear.
     </para>
    </step>
    <step>
     <para>
      If you are prompted to save your changes, click <guimenu>Save dashboard</guimenu>,
      optionally describe your changes, then click <guimenu>Save</guimenu>.
     </para>
    </step>
   </procedure>
   <para>
    You can now access this dashboard from the <guimenu>Home</guimenu> screen in
    &grafana;.
   </para>
  </sect2>
  <sect2 xml:id="sec-monitoring-compute-node-performance">
   <title>Monitoring compute node performance</title>
   <para>
    You can monitor the performance of your compute nodes with the &prometheus;
    node exporter. The node exporter gathers kernel and hardware metrics.
    To visualize these metrics, you can import a custom dashboard from the
    &grafana; website. For more information, see
    <link xlink:href="https://grafana.com/grafana/dashboards/405"/>.
   </para>
   <itemizedlist>
    <title>Prerequisites</title>
    <listitem>
     <para>
      <xref linkend="sec-installing-prometheus-grafana"/> is complete.
     </para>
    </listitem>
    <listitem>
     <para>
      You have internet access and policies that allow you to download the
      dashboard from the &grafana; website.
     </para>
    </listitem>
    <listitem>
     <para>
      To use <command>pdsh</command> to run commands on multiple nodes at once,
      <command>pdsh</command> must be installed on the client machine,
      and SSH key authentication must be configured for the nodes.
      <!--sec-remote-pdsh-->
     </para>
    </listitem>
   </itemizedlist>
   <procedure xml:id="pro-monitoring-compute-node-performance">
    <title>Monitoring compute node performance</title>
    <para>
     In this procedure, replace the example node names with the FQDNs or IP
    addresses of your nodes, and replace <literal>&exampledomain;</literal> with
    the FQDN or IP address of the server where &grafana; is installed.
    </para>
    <step>
     <para>
      On each compute node, install the node exporter:
     </para>
<screen>&prompt.root;zypper in golang-github-prometheus-node_exporter</screen>
     <para>
      To run this command on multiple nodes at once, you can use <command>pdsh</command>:
     </para>
<screen>&prompt.user;pdsh -R ssh -u root -w "node1.&exampledomain;,node2.&exampledomain;" \
"zypper in -y golang-github-prometheus-node_exporter"</screen>
    </step>
    <step>
     <para>
      Enable and start the node exporter:
    </para>
<screen>&prompt.root;systemctl enable --now prometheus-node_exporter</screen>
    <para>
     To run this command on multiple nodes at once, you can use <command>pdsh</command>:
    </para>
<screen>&prompt.user;pdsh -R ssh -u root -w "node1.&exampledomain;,node2.&exampledomain;" \
"systemctl enable --now prometheus-node_exporter"</screen>
    </step>
    <step>
     <para>
      Verify that the node exporter works:
     </para>
     <stepalternatives>
      <step>
       <para>
        In your browser, navigate to
        <link xlink:href="http://node1.&exampledomain;:9100/metrics"/>, or:
       </para>
      </step>
      <step>
       <para>
        In your terminal, run the following command:
       </para>
<screen>&prompt.user;wget http://node1.&exampledomain;:9100/metrics --output-document=-</screen>
      </step>
     </stepalternatives>
     <para>
      Either of these methods should show output similar to the following:
     </para>
<screen># HELP go_gc_duration_seconds A summary of the pause duration of garbage collection cycles.
# TYPE go_gc_duration_seconds summary
go_gc_duration_seconds{quantile="0"} 2.3937e-05
go_gc_duration_seconds{quantile="0.25"} 3.5456e-05
go_gc_duration_seconds{quantile="0.5"} 8.1436e-05
...</screen>
    </step>
    <step>
     <para>
      On the server where &prometheus; is installed, edit the
      <literal>scrape_configs</literal> section of the
      <filename>/etc/prometheus/prometheus.yml</filename> file
      to add a job for the node exporter:
    </para>
<screen>  - job_name: node-exporter
    static_configs:
      - targets: ['node1.&exampledomain;:9100']
      - targets: ['node2.&exampledomain;:9100']</screen>
     <para>
      Add a target for every node that has the node exporter installed.
     </para>
    </step>
    <step>
     <para>
      Restart the &prometheus; service:
     </para>
     <screen>&prompt.root;systemctl restart prometheus</screen>
    </step>
    <step>
     <para>
      Log in to the &grafana; web server at <link xlink:href="http://&exampledomain;:3000"/>.
     </para>
    </step>
    <step>
     <para>
      On the left panel, select &graf-create-icon; and click <guimenu>Import</guimenu>.
     </para>
    </step>
    <step>
     <para>
      In the <guimenu>Import via grafana.com</guimenu> field, enter the dashboard
      ID <literal>405</literal>, then click <guimenu>Load</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Select <guimenu>&prometheus;</guimenu> from the
      <guimenu>Select a &prometheus; data source</guimenu> drop-down box, then
      click <guimenu>Import</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Review the node exporter dashboard. You can click the <guimenu>node</guimenu>
      drop-down box to select the nodes you want to view. The data might take
      some time to appear.
     </para>
    </step>
    <step>
     <para>
      If you are prompted to save your changes, click <guimenu>Save dashboard</guimenu>.
      To keep the currently selected nodes next time you access the dashboard,
      activate <guimenu>Save current variable values as dashboard default</guimenu>.
      Optionally describe your changes, then click <guimenu>Save</guimenu>.
     </para>
    </step>
   </procedure>
   <para>
    You can now access this dashboard from the <guimenu>Home</guimenu> screen in
    &grafana;.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-monitoring-ganglia">
  <title>Ganglia &mdash; system monitoring</title>
  <para>
   Ganglia is a scalable distributed monitoring system for high-performance
   computing systems, such as clusters and grids. It is based on a
   hierarchical design targeted at federations of clusters.
  </para>
  <sect2 xml:id="sec-using-ganglia">
   <title>Using Ganglia</title>
   <para>
    To use Ganglia, make sure to install <package>ganglia-gmetad</package>
    on the management server, then start the Ganglia meta-daemon:
    <command>rcgmead start</command>. To make sure the service is started
    after a reboot, run: <command>systemctl enable gmetad</command>. On
    each cluster node which you want to monitor, install
    <package>ganglia-gmond</package>, start the service <command>rcgmond
    start</command> and make sure it is enabled to be started automatically
    after a reboot: <command>systemctl enable gmond</command>. To test
    whether the <systemitem class="daemon">gmond</systemitem> daemon has
    connected to the
    meta-daemon, run <command>gstat -a</command> and check that each node to
    be monitored is present in the output.
   </para>
  </sect2>
  <sect2 xml:id="sec-ganglia-btrfs">
   <title>Ganglia on Btrfs</title>
   <para>
    When using the Btrfs file system, the monitoring data will be lost after
    a rollback and the service <systemitem class="daemon">gmetad</systemitem>.
    To be fix this issue, either install the package
    <package>ganglia-gmetad-skip-bcheck</package> or create the file
    <filename>/etc/ganglia/no_btrfs_check</filename>.
   </para>
  </sect2>
  <sect2 xml:id="sec-ganglia-web">
   <title>Using the Ganglia Web interface</title>
   <para>
    Install <package>ganglia-web</package> on the management server.
    Depending on which PHP version is used (the default is PHP 7), enable it in
    Apache2: <command>a2enmod php7</command> or <command>a2enmod
    php7</command>. Then start Apache2 on this machine: <command>rcapache2
    start</command> and make sure it is started automatically after a
    reboot: <command>systemctl enable apache2</command>. The Ganglia Web
    interface should be accessible from
    <literal>http://<replaceable>MANAGEMENT_SERVER</replaceable>/ganglia</literal>.
   </para>
  </sect2>
 </sect1>
 <sect1 xml:id="sec-monitoring-ras">
  <title>rasdaemon &mdash; utility to log RAS error tracings</title>
  <para>
   <systemitem class="daemon">rasdaemon</systemitem> is a RAS
   (Reliability, Availability and Serviceability) logging tool. It records
   memory errors using EDAC (Error Detection and Correction) tracing events.
   EDAC drivers in the Linux kernel handle detection of ECC (Error Correction
   Code) errors from memory controllers.
  </para>
  <para>
   <systemitem class="daemon">rasdaemon</systemitem> can be used on large
   memory systems to track, record and localize memory errors and how they
   evolve over time to detect hardware degradation. Furthermore, it can be used
   to localize a faulty DIMM on the motherboard.
  </para>
  <para>
   To check whether the EDAC drivers are loaded, execute:
  </para>
<screen>&prompt;ras-mc-ctl --status</screen>
  <para>
   The command should return <literal>ras-mc-ctl: drivers are
   loaded</literal>. If it indicates that the drivers are not loaded, EDAC
   may not be supported on your board.
  </para>
  <para>
   To start <systemitem class="daemon">rasdaemon</systemitem>, run
   <command>systemctl start rasdaemon.service</command>.
   To start <systemitem class="daemon">rasdaemon</systemitem>
   automatically at boot time, execute <command>systemctl enable
   rasdaemon.service</command>. The daemon will log information to
   <filename>/var/log/messages</filename> and to an internal database. A
   summary of the stored errors can be obtained with:
  </para>
<screen>&prompt;ras-mc-ctl --summary</screen>
  <para>
   The errors stored in the database can be viewed with:
  </para>
<screen>&prompt;ras-mc-ctl --errors</screen>
  <para>
   Optionally, you can load the DIMM labels silk-screened on the system
   board to more easily identify the faulty DIMM. To do so, before starting
   <systemitem class="daemon">rasdaemon</systemitem>, run:
  </para>
<screen>&prompt;systemctl start ras-mc-ctl start</screen>
  <para>
   For this to work, you need to set up a layout description for the board.
   There are no descriptions supplied by default. To add a layout
   description, create a file with an arbitrary name in the directory
   <filename>/etc/ras/dimm_labels.d/</filename>. The format is:
  </para>
<screen>Vendor: <replaceable>MOTHERBOARD-VENDOR-NAME</replaceable>
Model: <replaceable>MOTHERBOARD-MODEL-NAME</replaceable>
  <replaceable>LABEL</replaceable>: <replaceable>MC</replaceable>.<replaceable>TOP</replaceable>.<replaceable>MID</replaceable>.<replaceable>LOW</replaceable></screen>
 </sect1>
</chapter>
